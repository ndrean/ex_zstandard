searchData={"items":[{"type":"module","title":"ExZstdZig","doc":"Elixir bindings for the Zstandard (zstd) compression library, implemented in Zig via Zigler.\n\nZstandard is a fast compression algorithm providing high compression ratios. This library\noffers a complete API for compression and decompression with multiple usage patterns.","ref":"ExZstdZig.html"},{"type":"module","title":"Features - ExZstdZig","doc":"- **One-shot compression/decompression** - Simple functions for complete data in memory\n- **Context-based operations** - Reusable contexts for better performance across multiple operations\n- **Streaming API** - Process large files without loading them entirely into memory\n- **Dictionary support** - Train dictionaries for better compression of similar small files\n- **Compression strategies** - Optimized presets for different data types (text, JSON, binary)\n- **File operations** - High-level functions for compressing/decompressing files","ref":"ExZstdZig.html#module-features"},{"type":"module","title":"Installation - ExZstdZig","doc":"Add to your `mix.exs`:\n\n```elixir\ndef deps do\n  [\n    {:ex_zstd_zig, \"~> 0.1.0\"}\n  ]\nend\n```\n\nRequires `libzstd` to be installed on your system:\n- macOS: `brew install zstd`\n- Ubuntu/Debian: `apt-get install libzstd-dev`\n- Fedora: `dnf install libzstd-devel`","ref":"ExZstdZig.html#module-installation"},{"type":"module","title":"Quick Start - ExZstdZig","doc":"","ref":"ExZstdZig.html#module-quick-start"},{"type":"module","title":"One-shot compression - ExZstdZig","doc":"```elixir\n# Compress data\ndata = \"Hello, World!\"\n{:ok, compressed} = ExZstdZig.compress(data, 3)\n\n# Decompress\n{:ok, decompressed} = ExZstdZig.decompress(compressed)\n```","ref":"ExZstdZig.html#module-one-shot-compression"},{"type":"module","title":"File compression - ExZstdZig","doc":"```elixir\n# Compress a file\n:ok = ExZstdZig.compress_file(\"input.txt\", \"output.txt.zst\")\n\n# Decompress a file\n:ok = ExZstdZig.decompress_file(\"output.txt.zst\", \"restored.txt\")\n```","ref":"ExZstdZig.html#module-file-compression"},{"type":"module","title":"Context reuse for better performance - ExZstdZig","doc":"```elixir\n# Create a context once (use recipe defaults for text compression)\n{:ok, cctx} = ExZstdZig.cctx_init(%{strategy: :text})\n\n# Compress multiple items\n{:ok, compressed1} = ExZstdZig.compress_with_ctx(cctx, data1)\n:ok = ExZstdZig.reset_compressor_session(cctx)\n{:ok, compressed2} = ExZstdZig.compress_with_ctx(cctx, data2)\n```","ref":"ExZstdZig.html#module-context-reuse-for-better-performance"},{"type":"module","title":"Streaming compression - ExZstdZig","doc":"The `compress_stream/3` function accepts three modes:\n\n- **`:continue_op`** - Better compression (buffers data, may produce no output)\n- **`:flush`** - Guaranteed output per chunk (for real-time streaming)\n- **`:end_frame`** - Finalize frame (required to complete compression)\n\n```elixir\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3, strategy: :balanced})\n\n# Option 1: Better compression with :continue_op (batch processing)\n{:ok, {out1, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk1, :continue_op)\n{:ok, {out2, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk2, :continue_op)\n{:ok, {final, _, _}} = ExZstdZig.compress_stream(cctx, <<>>, :end_frame)\ncompressed = IO.iodata_to_binary([out1, out2, final])\n\n# Option 2: Real-time streaming with :flush (HTTP, network)\n{:ok, {chunk1, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk1, :flush)\n{:ok, {chunk2, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk2, :flush)\n{:ok, {final, _, _}} = ExZstdZig.compress_stream(cctx, <<>>, :end_frame)\ncompressed = IO.iodata_to_binary([chunk1, chunk2, final])\n```","ref":"ExZstdZig.html#module-streaming-compression"},{"type":"module","title":"Dictionary compression - ExZstdZig","doc":"```elixir\n# Train a dictionary from sample data\nsamples = [sample1, sample2, sample3, ...]\n{:ok, dictionary} = ExZstdZig.train_dictionary(samples, 1024)\n\n# Compress with dictionary\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3})\n{:ok, compressed} = ExZstdZig.compress_with_dict(cctx, data, dictionary)\n\n# Decompress with dictionary\n{:ok, dctx} = ExZstdZig.dctx_init(nil)\n{:ok, decompressed} = ExZstdZig.decompress_with_dict(dctx, compressed, dictionary)\n```","ref":"ExZstdZig.html#module-dictionary-compression"},{"type":"module","title":"Compression Strategies - ExZstdZig","doc":"Each recipe provides optimized defaults for compression level and ZSTD algorithm:\n- `:fast` - Fastest compression (level 1, fast algorithm)\n- `:balanced` - Good balance of speed/ratio (level 3, dfast algorithm, default)\n- `:maximum` - Maximum compression (level 22, btultra2 algorithm)\n- `:text` - Optimized for text/code (level 9, btopt algorithm)\n- `:structured_data` - Optimized for JSON/XML (level 9, btultra algorithm)\n- `:binary` - Optimized for binary data (level 6, lazy2 algorithm)","ref":"ExZstdZig.html#module-compression-strategies"},{"type":"module","title":"Configuration Flexibility - ExZstdZig","doc":"You can use recipes in multiple ways:\n\n```elixir\n# Use recipe defaults (recommended)\n{:ok, cctx} = ExZstdZig.cctx_init(%{strategy: :text})\n# → level 9 + btopt algorithm\n\n# Override level while keeping recipe's algorithm\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 15, strategy: :text})\n# → level 15 + btopt algorithm\n\n# Custom level with default algorithm\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 5})\n# → level 5 + dfast algorithm\n\n# Use all defaults\n{:ok, cctx} = ExZstdZig.cctx_init(%{})\n# → level 3 + dfast algorithm\n```","ref":"ExZstdZig.html#module-configuration-flexibility"},{"type":"module","title":"Performance Tips - ExZstdZig","doc":"1. **Reuse contexts** - Creating contexts has overhead. Reuse them with `reset_*_session/1`\n2. **Choose appropriate level** - Level 3 is usually optimal. Higher levels give diminishing returns\n3. **Use dictionaries** - For many small similar files (< 1KB each)\n4. **Stream large files** - Use `compress_file/3` or streaming API for files > 100MB\n5. **Pick the right strategy** - Use `:text` for code, `:structured_data` for JSON/XML","ref":"ExZstdZig.html#module-performance-tips"},{"type":"module","title":"Function Categories - ExZstdZig","doc":"","ref":"ExZstdZig.html#module-function-categories"},{"type":"module","title":"One-shot Functions - ExZstdZig","doc":"- `compress/2`, `decompress/1` - Simple compression with tuple returns\n- `simple_compress/2`, `simple_auto_decompress/1` - Direct result or error","ref":"ExZstdZig.html#module-one-shot-functions"},{"type":"module","title":"Context Management - ExZstdZig","doc":"- `cctx_init/1`, `dctx_init/1` - Create compression/decompression contexts\n- `reset_compressor_session/1`, `reset_decompressor_session/1` - Reset for reuse","ref":"ExZstdZig.html#module-context-management"},{"type":"module","title":"Context-based Operations - ExZstdZig","doc":"- `compress_with_ctx/2`, `decompress_with_ctx/2` - Use existing contexts","ref":"ExZstdZig.html#module-context-based-operations"},{"type":"module","title":"Streaming - ExZstdZig","doc":"- `compress_stream/3`, `decompress_stream/2` - Process data in chunks\n- `decompress_unfold/2` - Convenient streaming decompression for in-memory binaries\n- `recommended_c_in_size/0`, `recommended_d_in_size/0` - Get optimal buffer sizes","ref":"ExZstdZig.html#module-streaming"},{"type":"module","title":"File Operations - ExZstdZig","doc":"- `compress_file/3`, `decompress_file/3` - Handle files without loading into memory","ref":"ExZstdZig.html#module-file-operations"},{"type":"module","title":"Dictionary Support - ExZstdZig","doc":"- `train_dictionary/2` - Train from sample data\n- `load_compression_dictionary/2`, `load_decompression_dictionary/2` - Load into contexts\n- `compress_with_dict/3`, `decompress_with_dict/3` - Compress/decompress with dictionary","ref":"ExZstdZig.html#module-dictionary-support"},{"type":"module","title":"Utilities - ExZstdZig","doc":"- `getDecompressedSize/1` - Get decompressed size from compressed data\n- `version/0` - Get zstd library version","ref":"ExZstdZig.html#module-utilities"},{"type":"function","title":"ExZstdZig.cctx_init/1","doc":"The compression context initialization function.\n It takes a CompressionConfig struct with optional compression_level (1-22) and optional strategy (CompressionRecipe).\n\n Usage:\n   - cctx_init(.{}) - Use defaults: level 3 + dfast strategy\n   - cctx_init(.{.strategy = .text}) - Use recipe defaults: level 9 + btopt strategy\n   - cctx_init(.{.compression_level = 15, .strategy = .text}) - Custom level with recipe strategy\n   - cctx_init(.{.compression_level = 5}) - Custom level with default strategy","ref":"ExZstdZig.html#cctx_init/1"},{"type":"function","title":"ExZstdZig.compress/2","doc":"Compress binary data with specified compression level (1-22).","ref":"ExZstdZig.html#compress/2"},{"type":"function","title":"ExZstdZig.compress_file/3","doc":"Compress a file using streaming compression and write to output file.\n\nThis function provides true streaming compression - data is read, compressed,\nand written in chunks without loading the entire file into memory.","ref":"ExZstdZig.html#compress_file/3"},{"type":"function","title":"Parameters - ExZstdZig.compress_file/3","doc":"- `input_path` - Path to the file to compress\n  - `output_path` - Path where compressed file will be written\n  - `opts` - Keyword list of options:\n    - `:cctx` - Existing compression context to reuse (optional). If not provided, a new context will be created.\n    - `:compression_level` - Compression level (1-22), default: 3 (ignored if `:cctx` is provided)\n    - `:strategy` - Compression strategy (`:fast`, `:balanced`, etc.), default: `:balanced` (ignored if `:cctx` is provided)\n    - `:chunk_size` - Size of chunks to read/process, default: recommended size from zstd\n    - `:mode` - `:flush` (guaranteed output per chunk) or `:continue_op` (better compression), default: `:flush`","ref":"ExZstdZig.html#compress_file/3-parameters"},{"type":"function","title":"Returns - ExZstdZig.compress_file/3","doc":"- `:ok` on success\n  - `{:error, reason}` on failure","ref":"ExZstdZig.html#compress_file/3-returns"},{"type":"function","title":"Examples - ExZstdZig.compress_file/3","doc":"# Auto-create context with defaults\n    iex> ExZstdZig.compress_file(\"input.txt\", \"output.txt.zst\")\n    :ok\n\n    # Auto-create context with custom settings\n    iex> ExZstdZig.compress_file(\"input.txt\", \"output.txt.zst\", compression_level: 10, strategy: :text)\n    :ok\n\n    # Reuse existing context for multiple files\n    iex> {:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 5, strategy: :fast})\n    iex> ExZstdZig.compress_file(\"file1.txt\", \"file1.txt.zst\", cctx: cctx)\n    iex> ExZstdZig.reset_compressor_session(cctx)\n    iex> ExZstdZig.compress_file(\"file2.txt\", \"file2.txt.zst\", cctx: cctx)\n    :ok","ref":"ExZstdZig.html#compress_file/3-examples"},{"type":"function","title":"ExZstdZig.compress_stream/3","doc":"Compress a chunk of data using streaming compression.\n Returns {:ok, {compressed_data, bytes_consumed, remaining_bytes}} or {:error, reason}\n\n Parameters:\n - ctx: Compression context created with cctx_init\n - input: Data to compress (all input will be consumed)\n - end_op: Operation mode (see below)\n\n EndOp modes:\n - :continue_op - Buffer data for better compression. May produce little/no output.\n                  Use when more data is coming.\n - :flush - Force output of buffered data into a complete block. Guarantees output.\n            Slightly reduces compression ratio. Use for real-time streaming.\n - :end_frame - Finalize and close the frame. Call with empty input (<<>>) after\n                all data is sent, or with the last chunk. Adds frame footer/checksum.\n\n Return values:\n - compressed_data: Compressed output (may be empty with :continue_op if buffering)\n - bytes_consumed: How many input bytes were processed (usually all)\n - remaining_bytes: Work remaining hint (0 = operation complete, >0 = call again)\n                    For :end_frame, if >0, call again with <<>> until it returns 0","ref":"ExZstdZig.html#compress_stream/3"},{"type":"function","title":"ExZstdZig.compress_with_ctx/2","doc":"Compress binary data using the provided compression context.","ref":"ExZstdZig.html#compress_with_ctx/2"},{"type":"function","title":"ExZstdZig.compress_with_dict/3","doc":"Compress data using a dictionary for better compression of small similar files.\n The dictionary should be trained on representative sample data.\n Uses the compression settings already configured in the context.","ref":"ExZstdZig.html#compress_with_dict/3"},{"type":"function","title":"ExZstdZig.dctx_init/1","doc":"The decompression context initialization function.\n It takes a max_window: Optional maximum window size as power of 2 (10-31), or `nil`.","ref":"ExZstdZig.html#dctx_init/1"},{"type":"function","title":"ExZstdZig.decompress/1","doc":"Decompress binary data with automatic output size detection.","ref":"ExZstdZig.html#decompress/1"},{"type":"function","title":"ExZstdZig.decompress_file/3","doc":"Decompress a file using streaming decompression and write to output file.\n\nThis function provides true streaming decompression - data is read, decompressed,\nand written in chunks without loading the entire file into memory.","ref":"ExZstdZig.html#decompress_file/3"},{"type":"function","title":"Parameters - ExZstdZig.decompress_file/3","doc":"- `input_path` - Path to the compressed file\n  - `output_path` - Path where decompressed file will be written\n  - `opts` - Keyword list of options:\n    - `:dctx` - Existing decompression context to reuse (optional). If not provided, a new context will be created.\n    - `:max_window` - Maximum window size for decompression (10-31), default: nil (ignored if `:dctx` is provided)\n    - `:chunk_size` - Size of chunks to read, default: recommended size from zstd","ref":"ExZstdZig.html#decompress_file/3-parameters"},{"type":"function","title":"Returns - ExZstdZig.decompress_file/3","doc":"- `:ok` on success\n  - `{:error, reason}` on failure","ref":"ExZstdZig.html#decompress_file/3-returns"},{"type":"function","title":"Examples - ExZstdZig.decompress_file/3","doc":"# Auto-create context with defaults\n    iex> ExZstdZig.decompress_file(\"input.txt.zst\", \"output.txt\")\n    :ok\n\n    # Auto-create context with max window size\n    iex> ExZstdZig.decompress_file(\"input.txt.zst\", \"output.txt\", max_window: 20)\n    :ok\n\n    # Reuse existing context for multiple files\n    iex> {:ok, dctx} = ExZstdZig.dctx_init(nil)\n    iex> ExZstdZig.decompress_file(\"file1.txt.zst\", \"file1.txt\", dctx: dctx)\n    iex> ExZstdZig.reset_decompressor_session(dctx)\n    iex> ExZstdZig.decompress_file(\"file2.txt.zst\", \"file2.txt\", dctx: dctx)\n    :ok","ref":"ExZstdZig.html#decompress_file/3-examples"},{"type":"function","title":"ExZstdZig.decompress_stream/2","doc":"Decompress a chunk of data using streaming decompression.\n Returns {:ok, {decompressed_data, bytes_consumed}} or {:error, reason}\n\n - decompressed_data: The decompressed output (may be empty if buffering)\n - bytes_consumed: How many bytes from input were consumed","ref":"ExZstdZig.html#decompress_stream/2"},{"type":"function","title":"ExZstdZig.decompress_unfold/2","doc":"Decompress a compressed binary using streaming decompression with `Stream.unfold`.\n\nThis function provides a convenient way to decompress data that's already in memory\nusing streaming decompression internally. It's useful when you have compressed data\nas a binary and want to decompress it efficiently without loading it all at once\ninto a single decompression call.","ref":"ExZstdZig.html#decompress_unfold/2"},{"type":"function","title":"When to use - ExZstdZig.decompress_unfold/2","doc":"- You have compressed data in memory (not a file)\n- The compressed data is moderately sized (< 100MB)\n- You want streaming decompression benefits without file I/O\n- You prefer a simpler API than manual `decompress_stream/2` calls","ref":"ExZstdZig.html#decompress_unfold/2-when-to-use"},{"type":"function","title":"Comparison with other methods - ExZstdZig.decompress_unfold/2","doc":"- Use `decompress/1` for small data when simplicity is preferred\n- Use `decompress_unfold/2` for medium-sized data in memory with streaming benefits\n- Use `decompress_file/3` for large files to avoid loading everything into memory","ref":"ExZstdZig.html#decompress_unfold/2-comparison-with-other-methods"},{"type":"function","title":"Parameters - ExZstdZig.decompress_unfold/2","doc":"- `input` - Compressed binary data\n  - `opts` - Keyword list of options:\n    - `:dctx` - Existing decompression context to reuse (optional)","ref":"ExZstdZig.html#decompress_unfold/2-parameters"},{"type":"function","title":"Returns - ExZstdZig.decompress_unfold/2","doc":"The decompressed binary (built in memory)","ref":"ExZstdZig.html#decompress_unfold/2-returns"},{"type":"function","title":"Examples - ExZstdZig.decompress_unfold/2","doc":"# Simple usage - decompress a binary\n    iex> compressed = File.read!(\"data.zst\")\n    iex> decompressed = ExZstdZig.decompress_unfold(compressed)\n    iex> byte_size(decompressed)\n    1024000\n\n    # Reuse context for multiple decompressions\n    iex> {:ok, dctx} = ExZstdZig.dctx_init(nil)\n    iex> data1 = ExZstdZig.decompress_unfold(compressed1, dctx: dctx)\n    iex> ExZstdZig.reset_decompressor_session(dctx)\n    iex> data2 = ExZstdZig.decompress_unfold(compressed2, dctx: dctx)","ref":"ExZstdZig.html#decompress_unfold/2-examples"},{"type":"function","title":"Notes - ExZstdZig.decompress_unfold/2","doc":"The entire decompressed result is built in memory. For very large data (> 100MB),\nprefer `decompress_file/3` which streams to disk.","ref":"ExZstdZig.html#decompress_unfold/2-notes"},{"type":"function","title":"ExZstdZig.decompress_with_ctx/2","doc":"Decompress binary data using the provided decompression context.","ref":"ExZstdZig.html#decompress_with_ctx/2"},{"type":"function","title":"ExZstdZig.decompress_with_dict/3","doc":"Decompress data that was compressed using a dictionary.\n Output size is automatically determined from the frame.","ref":"ExZstdZig.html#decompress_with_dict/3"},{"type":"function","title":"ExZstdZig.getDecompressedSize/1","doc":"Get the decompressed size from the compressed data frame header.","ref":"ExZstdZig.html#getDecompressedSize/1"},{"type":"function","title":"ExZstdZig.load_compression_dictionary/2","doc":"Load a dictionary into a compression context for reuse across multiple compressions.\n The dictionary remains loaded until a new one is loaded or the context is reset.","ref":"ExZstdZig.html#load_compression_dictionary/2"},{"type":"function","title":"ExZstdZig.load_decompression_dictionary/2","doc":"Load a dictionary into a decompression context for reuse across multiple decompressions.\n The dictionary remains loaded until a new one is loaded or the context is reset.","ref":"ExZstdZig.html#load_decompression_dictionary/2"},{"type":"function","title":"ExZstdZig.recommended_c_in_size/0","doc":"Returns the recommended input buffer size for streaming compression (typically 128KB)","ref":"ExZstdZig.html#recommended_c_in_size/0"},{"type":"function","title":"ExZstdZig.recommended_c_out_size/0","doc":"Returns the recommended output buffer size for streaming compression","ref":"ExZstdZig.html#recommended_c_out_size/0"},{"type":"function","title":"ExZstdZig.recommended_d_in_size/0","doc":"Returns the recommended input buffer size for streaming decompression (typically 128KB)","ref":"ExZstdZig.html#recommended_d_in_size/0"},{"type":"function","title":"ExZstdZig.recommended_d_out_size/0","doc":"Returns the recommended output buffer size for streaming decompression (typically 128KB)","ref":"ExZstdZig.html#recommended_d_out_size/0"},{"type":"function","title":"ExZstdZig.reset_compressor_session/1","doc":"Reset compression context to reuse for a new independent operation.\n Use this:\n - Between compressing different independent data streams\n - To clear learned dictionaries/patterns\n - When reusing context for a completely new operation","ref":"ExZstdZig.html#reset_compressor_session/1"},{"type":"function","title":"ExZstdZig.reset_decompressor_session/1","doc":"Reset decompression context to reuse for a new independent operation.\n Use this:\n - Between decompressing different independent data streams\n - To clear loaded dictionaries\n - When reusing context for a completely new operation","ref":"ExZstdZig.html#reset_decompressor_session/1"},{"type":"function","title":"ExZstdZig.simple_auto_decompress/1","doc":"Decompress binary data with automatic output size detection.","ref":"ExZstdZig.html#simple_auto_decompress/1"},{"type":"function","title":"ExZstdZig.simple_compress/2","doc":"Compress binary data with the specified `level` (1-22).\n Returns the compressed data or an error if compression fails.","ref":"ExZstdZig.html#simple_compress/2"},{"type":"function","title":"ExZstdZig.simple_decompress/2","doc":"Decompress binary data into a buffer of size `output_size`. Use `decompress` for automatic size detection instead.","ref":"ExZstdZig.html#simple_decompress/2"},{"type":"function","title":"ExZstdZig.train_dictionary/2","doc":"Train a dictionary from sample data for better compression of similar small files.\n\n Parameters:\n - samples: List of sample data buffers to train on (minimum 20 samples recommended)\n - dict_size: Target dictionary size in bytes (typically 100KB for small data)\n\n Returns {:ok, dictionary} on success, {:error, reason} on failure","ref":"ExZstdZig.html#train_dictionary/2"},{"type":"function","title":"ExZstdZig.version/0","doc":"","ref":"ExZstdZig.html#version/0"},{"type":"extras","title":"ExZstdZig","doc":"# ExZstdZig\n\nFast Zstandard (zstd) compression/decompression for Elixir, implemented with Zig NIFs via the wonderful Zigler library.\n\n![Zig support](https://img.shields.io/badge/Zig-0.15.1-color?logo=zig&color=%23f3ab20)\n![Static Badge](https://img.shields.io/badge/zigler-0.15.1-orange)\n![Static Badge](https://img.shields.io/badge/zstd_1.5.7-green)\n\nZstandard is a fast compression algorithm offering high compression ratios. This library provides complete bindings with support for one-shot operations, streaming, context reuse, and dictionary training.","ref":"readme.html"},{"type":"extras","title":"Features - ExZstdZig","doc":"- **Fast** - Native implementation using Zig with minimal overhead\n- **Streaming** - Process large files without loading them into memory\n- **Context reuse** - Better performance when compressing multiple items\n- **Dictionary support** - Improved compression for similar small files\n- **Compression strategies** - Optimized presets for different data types\n- **Complete API** - From simple one-shot to advanced streaming operations","ref":"readme.html#features"},{"type":"extras","title":"Installation - ExZstdZig","doc":"Add `ex_zstd_zig` to your list of dependencies in `mix.exs`:\n\n```elixir\ndef deps do\n  [\n    {:ex_zstd_zig, \"~> 0.1.0\"}\n  ]\nend\n```","ref":"readme.html#installation"},{"type":"extras","title":"System Requirements - ExZstdZig","doc":"The library requires `libzstd` to be installed on your system:\n\n**macOS:**\n\n```bash\nbrew install zstd\n```\n\n**Ubuntu/Debian:**\n\n```bash\nsudo apt-get install libzstd-dev\n```","ref":"readme.html#system-requirements"},{"type":"extras","title":"Quick Start - ExZstdZig","doc":"","ref":"readme.html#quick-start"},{"type":"extras","title":"Simple Compression - ExZstdZig","doc":"```elixir\n# Compress data\ndata = \"Hello, World!\"\n{:ok, compressed} = ExZstdZig.compress(data, 3)\n\n# Decompress\n{:ok, decompressed} = ExZstdZig.decompress(compressed)\n```","ref":"readme.html#simple-compression"},{"type":"extras","title":"File Compression with streams - ExZstdZig","doc":"```elixir\n# Compress a file\n:ok = ExZstdZig.compress_file(\"input.txt\", \"output.txt.zst\")\n\n# Decompress a file\n:ok = ExZstdZig.decompress_file(\"output.txt.zst\", \"restored.txt\")\n```","ref":"readme.html#file-compression-with-streams"},{"type":"extras","title":"Context Reuse (Better Performance) - ExZstdZig","doc":"```elixir\n# Create a context once (use recipe defaults for text compression)\n{:ok, cctx} = ExZstdZig.cctx_init(%{strategy: :text})\n\n# Compress multiple items efficiently\n{:ok, compressed1} = ExZstdZig.compress_with_ctx(cctx, data1)\n\n# Reset and reuse\n:ok = ExZstdZig.reset_compressor_session(cctx)\n{:ok, compressed2} = ExZstdZig.compress_with_ctx(cctx, data2)\n```","ref":"readme.html#context-reuse-better-performance"},{"type":"extras","title":"Streaming Compression - ExZstdZig","doc":"The `compress_stream/3` function accepts three modes that control buffering and output:\n\n**`:continue_op`** - Better compression, batch processing\n- Buffers data for better compression ratios\n- May produce no output (buffering internally)\n- Use when: Processing data in batches, compression ratio matters more than latency\n\n**`:flush`** - Guaranteed output, real-time streaming\n- Forces output for each chunk (guarantees non-empty result)\n- Slightly reduces compression ratio\n- Use when: Real-time streaming (HTTP, network), need output per chunk\n\n**`:end_frame`** - Finalize frame\n- Closes the compression frame with footer/checksum\n- Call with empty input `<<>>` after last data chunk\n- Required to complete valid compressed data\n\n#### Example: Better compression with `:continue_op`\n\n```elixir\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3, strategy: :balanced})\n\n# Buffer data for better compression (may produce empty chunks)\n{:ok, {out1, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk1, :continue_op)\n{:ok, {out2, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk2, :continue_op)\n{:ok, {out3, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk3, :continue_op)\n\n# Finalize frame\n{:ok, {final, _, _}} = ExZstdZig.compress_stream(cctx, <<>>, :end_frame)\n\n# Some outputs may be empty if data was buffered\ncompressed = IO.iodata_to_binary([out1, out2, out3, final])\n```\n\n#### Example: Real-time streaming with `:flush`\n\n```elixir\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3, strategy: :balanced})\n\n# Force output for each chunk (guaranteed non-empty)\n{:ok, {chunk1, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk1, :flush)\n{:ok, {chunk2, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk2, :flush)\n{:ok, {chunk3, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk3, :flush)\n\n# Finalize frame\n{:ok, {final, _, _}} = ExZstdZig.compress_stream(cctx, <<>>, :end_frame)\n\n# All chunks contain data (good for streaming)\ncompressed = IO.iodata_to_binary([chunk1, chunk2, chunk3, final])\n```","ref":"readme.html#streaming-compression"},{"type":"extras","title":"In-Memory Streaming Decompression - ExZstdZig","doc":"For moderately-sized compressed data in memory, use `decompress_unfold/2`:\n\n```elixir\n# Decompress a binary with streaming (efficient for medium-sized data)\ncompressed = File.read!(\"data.zst\")\ndecompressed = ExZstdZig.decompress_unfold(compressed)\n```","ref":"readme.html#in-memory-streaming-decompression"},{"type":"extras","title":"Dictionary Training - ExZstdZig","doc":"Train a dictionary for better compression of many small similar files:\n\n```elixir\n# Collect sample data\nsamples = [\n  ~s({\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\"}),\n  ~s({\"id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\"}),\n  # ... more samples\n]\n\n# Train dictionary\n{:ok, dictionary} = ExZstdZig.train_dictionary(samples, 1024)\n\n# Compress with dictionary\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3, strategy: :structured_data})\n{:ok, compressed} = ExZstdZig.compress_with_dict(cctx, new_data, dictionary)\n\n# Decompress with dictionary\n{:ok, dctx} = ExZstdZig.dctx_init(nil)\n{:ok, decompressed} = ExZstdZig.decompress_with_dict(dctx, compressed, dictionary)\n```","ref":"readme.html#dictionary-training"},{"type":"extras","title":"Compression Strategies - ExZstdZig","doc":"Choose the right strategy for your data type. Each recipe provides optimized defaults for compression level and ZSTD algorithm:\n\n- `:fast` - Fastest compression (level 1, fast algorithm)\n- `:balanced` - Good balance (level 3, dfast algorithm, **default**)\n- `:maximum` - Maximum compression (level 22, btultra2 algorithm)\n- `:text` - Optimized for text/code (level 9, btopt algorithm)\n- `:structured_data` - Optimized for JSON/XML (level 9, btultra algorithm)\n- `:binary` - Optimized for binary data (level 6, lazy2 algorithm)","ref":"readme.html#compression-strategies"},{"type":"extras","title":"Configuration Options - ExZstdZig","doc":"```elixir\n# Use recipe defaults (recommended)\n{:ok, cctx} = ExZstdZig.cctx_init(%{strategy: :text})\n# → level 9 + btopt algorithm\n\n{:ok, cctx} = ExZstdZig.cctx_init(%{strategy: :structured_data})\n# → level 9 + btultra algorithm\n\n# Override level while keeping recipe's algorithm\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 15, strategy: :text})\n# → level 15 + btopt algorithm\n\n# Custom level with default algorithm\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 5})\n# → level 5 + dfast algorithm\n\n# Use all defaults\n{:ok, cctx} = ExZstdZig.cctx_init(%{})\n# → level 3 + dfast algorithm\n```","ref":"readme.html#configuration-options"},{"type":"extras","title":"Performance Tips - ExZstdZig","doc":"1. **Reuse contexts** - Creating contexts has overhead. Reuse them for multiple operations\n2. **Choose appropriate level** - Level 3 is usually optimal. Higher levels give diminishing returns\n3. **Use dictionaries** - For compressing many small similar files (< 1KB each)\n4. **Stream large files** - Use `compress_file/3` or streaming API for files > 100MB\n5. **Pick the right strategy** - Match the strategy to your data type","ref":"readme.html#performance-tips"},{"type":"extras","title":"HTTP Streaming - ExZstdZig","doc":"","ref":"readme.html#http-streaming"},{"type":"extras","title":"Compression: On-the-fly - ExZstdZig","doc":"You **can** compress data on-the-fly during HTTP downloads because compression is fast enough:\n\n```elixir\n# Use level 3 for speed (level 9 would be too slow for on-the-fly compression)\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3, strategy: :structured_data})\ncompressed_pid = File.open!(\"output.zst\", [:write, :binary])\n\nReq.get!(\"https://example.com/large-file.json\",\n  into: fn\n    {:data, chunk}, {req, resp} ->\n      # Compress each chunk as it arrives (use :flush for guaranteed output)\n      {:ok, {compressed, _, _}} = ExZstdZig.compress_stream(cctx, chunk, :flush)\n      :ok = IO.binwrite(compressed_pid, compressed)\n      {:cont, {req, resp}}\n  end\n)\n\n# Finalize the compression frame\n{:ok, {final, _, _}} = ExZstdZig.compress_stream(cctx, <<>>, :end_frame)\nIO.binwrite(compressed_pid, final)\nFile.close(compressed_pid)\n```","ref":"readme.html#compression-on-the-fly"},{"type":"extras","title":"Decompression: 2-Step Process ⚠️ - ExZstdZig","doc":"You **cannot** decompress on-the-fly in HTTP callbacks due to HTTP/2 back-pressure limitations. Use a 2-step process:\n\n```elixir\n# Step 1: Download compressed file (fast callback)\ncompressed_pid = File.open!(\"download.zst\", [:write, :binary])\n\nReq.get!(\"https://example.com/compressed-file.zst\",\n  into: fn\n    {:data, chunk}, {req, resp} ->\n      :ok = IO.binwrite(compressed_pid, chunk)\n      {:cont, {req, resp}}\n  end\n)\n\nFile.close(compressed_pid)\n\n# Step 2: Decompress using streaming decompression\n{:ok, dctx} = ExZstdZig.dctx_init(nil)\nExZstdZig.decompress_file(\"download.zst\", \"output.txt\", dctx: dctx)\n```\n\n**Why?** HTTP/2 (used by Finch/Req) has no back-pressure mechanism. Decompression + file I/O in callbacks is too slow, causing connection timeouts and data loss.","ref":"readme.html#decompression-2-step-process-️"},{"type":"extras","title":"API Overview - ExZstdZig","doc":"","ref":"readme.html#api-overview"},{"type":"extras","title":"One-shot Functions - ExZstdZig","doc":"- `compress/2` - Compress data, returns `{:ok, compressed}`\n- `decompress/1` - Decompress data, returns `{:ok, decompressed}`\n- `simple_compress/2` - Direct compression (raises on error)\n- `simple_auto_decompress/1` - Direct decompression (raises on error)","ref":"readme.html#one-shot-functions"},{"type":"extras","title":"Context Management - ExZstdZig","doc":"- `cctx_init/1` - Create compression context\n- `dctx_init/1` - Create decompression context\n- `reset_compressor_session/1` - Reset compression context for reuse\n- `reset_decompressor_session/1` - Reset decompression context for reuse","ref":"readme.html#context-management"},{"type":"extras","title":"Context-based Operations - ExZstdZig","doc":"- `compress_with_ctx/2` - Compress using context\n- `decompress_with_ctx/2` - Decompress using context","ref":"readme.html#context-based-operations"},{"type":"extras","title":"Streaming - ExZstdZig","doc":"- `compress_stream/3` - Compress data in chunks\n- `decompress_stream/2` - Decompress data in chunks\n- `decompress_unfold/2` - Convenient streaming decompression for in-memory binaries\n- `recommended_c_in_size/0` - Get recommended input buffer size for compression\n- `recommended_d_in_size/0` - Get recommended input buffer size for decompression","ref":"readme.html#streaming"},{"type":"extras","title":"File Operations - ExZstdZig","doc":"- `compress_file/3` - Compress file (streaming, low memory)\n- `decompress_file/3` - Decompress file (streaming, low memory)","ref":"readme.html#file-operations"},{"type":"extras","title":"Dictionary Support - ExZstdZig","doc":"- `train_dictionary/2` - Train dictionary from samples\n- `load_compression_dictionary/2` - Load dictionary into compression context\n- `load_decompression_dictionary/2` - Load dictionary into decompression context\n- `compress_with_dict/3` - One-shot compression with dictionary\n- `decompress_with_dict/3` - One-shot decompression with dictionary","ref":"readme.html#dictionary-support"},{"type":"extras","title":"Utilities - ExZstdZig","doc":"- `getDecompressedSize/1` - Get decompressed size from compressed data\n- `version/0` - Get zstd library version","ref":"readme.html#utilities"},{"type":"extras","title":"Documentation - ExZstdZig","doc":"Full documentation is available at [HexDocs](https://hexdocs.pm/ex_zstd_zig) (once published).\n\nTo generate documentation locally:\n\n```bash\nmix docs\n```\n\nThen open `doc/index.html` in your browser.","ref":"readme.html#documentation"},{"type":"extras","title":"License - ExZstdZig","doc":"MIT License - see [LICENSE](LICENSE) for details.","ref":"readme.html#license"},{"type":"extras","title":"Credits - ExZstdZig","doc":"- Built with [Zigler](https://github.com/E-xyza/zigler)\n- Uses [Zstandard](https://facebook.github.io/zstd/) compression library","ref":"readme.html#credits"}],"proglang":"elixir","content_type":"text/markdown","producer":{"name":"ex_doc","version":"0.38.4"}}