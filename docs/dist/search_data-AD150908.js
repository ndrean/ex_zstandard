searchData={"items":[{"type":"module","doc":"Elixir bindings for the Zstandard (zstd) compression library, implemented in Zig via Zigler.\n\nZstandard is a fast compression algorithm providing high compression ratios. This library\noffers a complete API for compression and decompression with multiple usage patterns.","title":"ExZstdZig","ref":"ExZstdZig.html"},{"type":"module","doc":"- **One-shot compression/decompression** - Simple functions for complete data in memory\n- **Context-based operations** - Reusable contexts for better performance across multiple operations\n- **Streaming API** - Process large files without loading them entirely into memory\n- **Dictionary support** - Train dictionaries for better compression of similar small files\n- **Compression strategies** - Optimized presets for different data types (text, JSON, binary)\n- **File operations** - High-level functions for compressing/decompressing files","title":"Features - ExZstdZig","ref":"ExZstdZig.html#module-features"},{"type":"module","doc":"Add to your `mix.exs`:\n\n```elixir\ndef deps do\n  [\n    {:ex_zstd_zig, \"~> 0.1.0\"}\n  ]\nend\n```\n\nRequires `libzstd` to be installed on your system:\n- macOS: `brew install zstd`\n- Ubuntu/Debian: `apt-get install libzstd-dev`\n- Fedora: `dnf install libzstd-devel`","title":"Installation - ExZstdZig","ref":"ExZstdZig.html#module-installation"},{"type":"module","doc":"","title":"Quick Start - ExZstdZig","ref":"ExZstdZig.html#module-quick-start"},{"type":"module","doc":"```elixir\n# Compress data\ndata = \"Hello, World!\"\n{:ok, compressed} = ExZstdZig.compress(data, 3)\n\n# Decompress\n{:ok, decompressed} = ExZstdZig.decompress(compressed)\n```","title":"One-shot compression - ExZstdZig","ref":"ExZstdZig.html#module-one-shot-compression"},{"type":"module","doc":"```elixir\n# Compress a file\n:ok = ExZstdZig.compress_file(\"input.txt\", \"output.txt.zst\")\n\n# Decompress a file\n:ok = ExZstdZig.decompress_file(\"output.txt.zst\", \"restored.txt\")\n```","title":"File compression - ExZstdZig","ref":"ExZstdZig.html#module-file-compression"},{"type":"module","doc":"```elixir\n# Create a context once\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 5, strategy: :text})\n\n# Compress multiple items\n{:ok, compressed1} = ExZstdZig.compress_with_ctx(cctx, data1)\n:ok = ExZstdZig.reset_compressor_session(cctx)\n{:ok, compressed2} = ExZstdZig.compress_with_ctx(cctx, data2)\n```","title":"Context reuse for better performance - ExZstdZig","ref":"ExZstdZig.html#module-context-reuse-for-better-performance"},{"type":"module","doc":"```elixir\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3, strategy: :balanced})\n\n# Compress in chunks\n{:ok, {chunk1, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk1, :flush)\n{:ok, {chunk2, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk2, :flush)\n{:ok, {final, _, _}} = ExZstdZig.compress_stream(cctx, <<>>, :end_frame)\n\ncompressed = IO.iodata_to_binary([chunk1, chunk2, final])\n```","title":"Streaming compression - ExZstdZig","ref":"ExZstdZig.html#module-streaming-compression"},{"type":"module","doc":"```elixir\n# Train a dictionary from sample data\nsamples = [sample1, sample2, sample3, ...]\n{:ok, dictionary} = ExZstdZig.train_dictionary(samples, 1024)\n\n# Compress with dictionary\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3})\n{:ok, compressed} = ExZstdZig.compress_with_dict(cctx, data, dictionary)\n\n# Decompress with dictionary\n{:ok, dctx} = ExZstdZig.dctx_init(nil)\n{:ok, decompressed} = ExZstdZig.decompress_with_dict(dctx, compressed, dictionary)\n```","title":"Dictionary compression - ExZstdZig","ref":"ExZstdZig.html#module-dictionary-compression"},{"type":"module","doc":"Available strategies for different data types:\n- `:fast` - Fastest compression (level 1)\n- `:balanced` - Good balance of speed/ratio (level 3, default)\n- `:maximum` - Maximum compression (level 22)\n- `:text` - Optimized for text/code (level 9)\n- `:structured_data` - Optimized for JSON/XML (level 9)\n- `:binary` - Optimized for binary data (level 6)","title":"Compression Strategies - ExZstdZig","ref":"ExZstdZig.html#module-compression-strategies"},{"type":"module","doc":"1. **Reuse contexts** - Creating contexts has overhead. Reuse them with `reset_*_session/1`\n2. **Choose appropriate level** - Level 3 is usually optimal. Higher levels give diminishing returns\n3. **Use dictionaries** - For many small similar files (< 1KB each)\n4. **Stream large files** - Use `compress_file/3` or streaming API for files > 100MB\n5. **Pick the right strategy** - Use `:text` for code, `:structured_data` for JSON/XML","title":"Performance Tips - ExZstdZig","ref":"ExZstdZig.html#module-performance-tips"},{"type":"module","doc":"","title":"Function Categories - ExZstdZig","ref":"ExZstdZig.html#module-function-categories"},{"type":"module","doc":"- `compress/2`, `decompress/1` - Simple compression with tuple returns\n- `simple_compress/2`, `simple_auto_decompress/1` - Direct result or error","title":"One-shot Functions - ExZstdZig","ref":"ExZstdZig.html#module-one-shot-functions"},{"type":"module","doc":"- `cctx_init/1`, `dctx_init/1` - Create compression/decompression contexts\n- `reset_compressor_session/1`, `reset_decompressor_session/1` - Reset for reuse","title":"Context Management - ExZstdZig","ref":"ExZstdZig.html#module-context-management"},{"type":"module","doc":"- `compress_with_ctx/2`, `decompress_with_ctx/2` - Use existing contexts","title":"Context-based Operations - ExZstdZig","ref":"ExZstdZig.html#module-context-based-operations"},{"type":"module","doc":"- `compress_stream/3`, `decompress_stream/2` - Process data in chunks\n- `recommended_c_in_size/0`, `recommended_d_in_size/0` - Get optimal buffer sizes","title":"Streaming - ExZstdZig","ref":"ExZstdZig.html#module-streaming"},{"type":"module","doc":"- `compress_file/3`, `decompress_file/3` - Handle files without loading into memory","title":"File Operations - ExZstdZig","ref":"ExZstdZig.html#module-file-operations"},{"type":"module","doc":"- `train_dictionary/2` - Train from sample data\n- `load_compression_dictionary/2`, `load_decompression_dictionary/2` - Load into contexts\n- `compress_with_dict/3`, `decompress_with_dict/3` - Compress/decompress with dictionary","title":"Dictionary Support - ExZstdZig","ref":"ExZstdZig.html#module-dictionary-support"},{"type":"module","doc":"- `getDecompressedSize/1` - Get decompressed size from compressed data\n- `version/0` - Get zstd library version","title":"Utilities - ExZstdZig","ref":"ExZstdZig.html#module-utilities"},{"type":"function","doc":"The compression context initialization function.\n It takes a CompressionConfig struct with compression_level (1-22) and optional strategy (CompressionRecipe).\n The default config, .{}, is level 3 with balanced compression strategy.","title":"ExZstdZig.cctx_init/1","ref":"ExZstdZig.html#cctx_init/1"},{"type":"function","doc":"Compress binary data with specified compression level (1-22).","title":"ExZstdZig.compress/2","ref":"ExZstdZig.html#compress/2"},{"type":"function","doc":"Compress a file using streaming compression and write to output file.\n\nThis function provides true streaming compression - data is read, compressed,\nand written in chunks without loading the entire file into memory.","title":"ExZstdZig.compress_file/3","ref":"ExZstdZig.html#compress_file/3"},{"type":"function","doc":"- `input_path` - Path to the file to compress\n  - `output_path` - Path where compressed file will be written\n  - `opts` - Keyword list of options:\n    - `:cctx` - Existing compression context to reuse (optional). If not provided, a new context will be created.\n    - `:compression_level` - Compression level (1-22), default: 3 (ignored if `:cctx` is provided)\n    - `:strategy` - Compression strategy (`:fast`, `:balanced`, etc.), default: `:balanced` (ignored if `:cctx` is provided)\n    - `:chunk_size` - Size of chunks to read/process, default: recommended size from zstd\n    - `:mode` - `:flush` (guaranteed output per chunk) or `:continue_op` (better compression), default: `:flush`","title":"Parameters - ExZstdZig.compress_file/3","ref":"ExZstdZig.html#compress_file/3-parameters"},{"type":"function","doc":"- `:ok` on success\n  - `{:error, reason}` on failure","title":"Returns - ExZstdZig.compress_file/3","ref":"ExZstdZig.html#compress_file/3-returns"},{"type":"function","doc":"# Auto-create context with defaults\n    iex> ExZstdZig.compress_file(\"input.txt\", \"output.txt.zst\")\n    :ok\n\n    # Auto-create context with custom settings\n    iex> ExZstdZig.compress_file(\"input.txt\", \"output.txt.zst\", compression_level: 10, strategy: :text)\n    :ok\n\n    # Reuse existing context for multiple files\n    iex> {:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 5, strategy: :fast})\n    iex> ExZstdZig.compress_file(\"file1.txt\", \"file1.txt.zst\", cctx: cctx)\n    iex> ExZstdZig.reset_compressor_session(cctx)\n    iex> ExZstdZig.compress_file(\"file2.txt\", \"file2.txt.zst\", cctx: cctx)\n    :ok","title":"Examples - ExZstdZig.compress_file/3","ref":"ExZstdZig.html#compress_file/3-examples"},{"type":"function","doc":"Compress a chunk of data using streaming compression.\n Returns {:ok, {compressed_data, bytes_consumed, remaining_bytes}} or {:error, reason}\n\n Parameters:\n - ctx: Compression context created with cctx_init\n - input: Data to compress (all input will be consumed)\n - end_op: Operation mode (see below)\n\n EndOp modes:\n - :continue_op - Buffer data for better compression. May produce little/no output.\n                  Use when more data is coming.\n - :flush - Force output of buffered data into a complete block. Guarantees output.\n            Slightly reduces compression ratio. Use for real-time streaming.\n - :end_frame - Finalize and close the frame. Call with empty input (<<>>) after\n                all data is sent, or with the last chunk. Adds frame footer/checksum.\n\n Return values:\n - compressed_data: Compressed output (may be empty with :continue_op if buffering)\n - bytes_consumed: How many input bytes were processed (usually all)\n - remaining_bytes: Work remaining hint (0 = operation complete, >0 = call again)\n                    For :end_frame, if >0, call again with <<>> until it returns 0","title":"ExZstdZig.compress_stream/3","ref":"ExZstdZig.html#compress_stream/3"},{"type":"function","doc":"Compress binary data using the provided compression context.","title":"ExZstdZig.compress_with_ctx/2","ref":"ExZstdZig.html#compress_with_ctx/2"},{"type":"function","doc":"Compress data using a dictionary for better compression of small similar files.\n The dictionary should be trained on representative sample data.\n Uses the compression settings already configured in the context.","title":"ExZstdZig.compress_with_dict/3","ref":"ExZstdZig.html#compress_with_dict/3"},{"type":"function","doc":"The decompression context initialization function.\n It takes a max_window: Optional maximum window size as power of 2 (10-31), or `nil`.","title":"ExZstdZig.dctx_init/1","ref":"ExZstdZig.html#dctx_init/1"},{"type":"function","doc":"Decompress binary data with automatic output size detection.","title":"ExZstdZig.decompress/1","ref":"ExZstdZig.html#decompress/1"},{"type":"function","doc":"Decompress a file using streaming decompression and write to output file.\n\nThis function provides true streaming decompression - data is read, decompressed,\nand written in chunks without loading the entire file into memory.","title":"ExZstdZig.decompress_file/3","ref":"ExZstdZig.html#decompress_file/3"},{"type":"function","doc":"- `input_path` - Path to the compressed file\n  - `output_path` - Path where decompressed file will be written\n  - `opts` - Keyword list of options:\n    - `:dctx` - Existing decompression context to reuse (optional). If not provided, a new context will be created.\n    - `:max_window` - Maximum window size for decompression (10-31), default: nil (ignored if `:dctx` is provided)\n    - `:chunk_size` - Size of chunks to read, default: recommended size from zstd","title":"Parameters - ExZstdZig.decompress_file/3","ref":"ExZstdZig.html#decompress_file/3-parameters"},{"type":"function","doc":"- `:ok` on success\n  - `{:error, reason}` on failure","title":"Returns - ExZstdZig.decompress_file/3","ref":"ExZstdZig.html#decompress_file/3-returns"},{"type":"function","doc":"# Auto-create context with defaults\n    iex> ExZstdZig.decompress_file(\"input.txt.zst\", \"output.txt\")\n    :ok\n\n    # Auto-create context with max window size\n    iex> ExZstdZig.decompress_file(\"input.txt.zst\", \"output.txt\", max_window: 20)\n    :ok\n\n    # Reuse existing context for multiple files\n    iex> {:ok, dctx} = ExZstdZig.dctx_init(nil)\n    iex> ExZstdZig.decompress_file(\"file1.txt.zst\", \"file1.txt\", dctx: dctx)\n    iex> ExZstdZig.reset_decompressor_session(dctx)\n    iex> ExZstdZig.decompress_file(\"file2.txt.zst\", \"file2.txt\", dctx: dctx)\n    :ok","title":"Examples - ExZstdZig.decompress_file/3","ref":"ExZstdZig.html#decompress_file/3-examples"},{"type":"function","doc":"Decompress a chunk of data using streaming decompression.\n Returns {:ok, {decompressed_data, bytes_consumed}} or {:error, reason}\n\n - decompressed_data: The decompressed output (may be empty if buffering)\n - bytes_consumed: How many bytes from input were consumed","title":"ExZstdZig.decompress_stream/2","ref":"ExZstdZig.html#decompress_stream/2"},{"type":"function","doc":"Decompress a full binary and generate the full decompressed binary using Stream.unfold.\nThis is a faster convenience function for smaller data where you want to use streaming.\nThe resulting binary is built in memory and may be further saved to a file or processed.","title":"ExZstdZig.decompress_unfold/2","ref":"ExZstdZig.html#decompress_unfold/2"},{"type":"function","doc":"Decompress binary data using the provided decompression context.","title":"ExZstdZig.decompress_with_ctx/2","ref":"ExZstdZig.html#decompress_with_ctx/2"},{"type":"function","doc":"Decompress data that was compressed using a dictionary.\n Output size is automatically determined from the frame.","title":"ExZstdZig.decompress_with_dict/3","ref":"ExZstdZig.html#decompress_with_dict/3"},{"type":"function","doc":"Get the decompressed size from the compressed data frame header.","title":"ExZstdZig.getDecompressedSize/1","ref":"ExZstdZig.html#getDecompressedSize/1"},{"type":"function","doc":"Load a dictionary into a compression context for reuse across multiple compressions.\n The dictionary remains loaded until a new one is loaded or the context is reset.","title":"ExZstdZig.load_compression_dictionary/2","ref":"ExZstdZig.html#load_compression_dictionary/2"},{"type":"function","doc":"Load a dictionary into a decompression context for reuse across multiple decompressions.\n The dictionary remains loaded until a new one is loaded or the context is reset.","title":"ExZstdZig.load_decompression_dictionary/2","ref":"ExZstdZig.html#load_decompression_dictionary/2"},{"type":"function","doc":"Returns the recommended input buffer size for streaming compression (typically 128KB)","title":"ExZstdZig.recommended_c_in_size/0","ref":"ExZstdZig.html#recommended_c_in_size/0"},{"type":"function","doc":"Returns the recommended output buffer size for streaming compression","title":"ExZstdZig.recommended_c_out_size/0","ref":"ExZstdZig.html#recommended_c_out_size/0"},{"type":"function","doc":"Returns the recommended input buffer size for streaming decompression (typically 128KB)","title":"ExZstdZig.recommended_d_in_size/0","ref":"ExZstdZig.html#recommended_d_in_size/0"},{"type":"function","doc":"Returns the recommended output buffer size for streaming decompression (typically 128KB)","title":"ExZstdZig.recommended_d_out_size/0","ref":"ExZstdZig.html#recommended_d_out_size/0"},{"type":"function","doc":"Reset compression context to reuse for a new independent operation.\n Use this:\n - Between compressing different independent data streams\n - To clear learned dictionaries/patterns\n - When reusing context for a completely new operation","title":"ExZstdZig.reset_compressor_session/1","ref":"ExZstdZig.html#reset_compressor_session/1"},{"type":"function","doc":"Reset decompression context to reuse for a new independent operation.\n Use this:\n - Between decompressing different independent data streams\n - To clear loaded dictionaries\n - When reusing context for a completely new operation","title":"ExZstdZig.reset_decompressor_session/1","ref":"ExZstdZig.html#reset_decompressor_session/1"},{"type":"function","doc":"Decompress binary data with automatic output size detection.","title":"ExZstdZig.simple_auto_decompress/1","ref":"ExZstdZig.html#simple_auto_decompress/1"},{"type":"function","doc":"Compress binary data with the specified `level` (1-22).\n Returns the compressed data or an error if compression fails.","title":"ExZstdZig.simple_compress/2","ref":"ExZstdZig.html#simple_compress/2"},{"type":"function","doc":"Decompress binary data into a buffer of size `output_size`. Use `decompress` for automatic size detection instead.","title":"ExZstdZig.simple_decompress/2","ref":"ExZstdZig.html#simple_decompress/2"},{"type":"function","doc":"Train a dictionary from sample data for better compression of similar small files.\n\n Parameters:\n - samples: List of sample data buffers to train on (minimum 20 samples recommended)\n - dict_size: Target dictionary size in bytes (typically 100KB for small data)\n\n Returns {:ok, dictionary} on success, {:error, reason} on failure","title":"ExZstdZig.train_dictionary/2","ref":"ExZstdZig.html#train_dictionary/2"},{"type":"function","doc":"","title":"ExZstdZig.version/0","ref":"ExZstdZig.html#version/0"},{"type":"module","doc":"Provides git repository information for the ExZstdZig project.","title":"ExZstdZig.GitInfo","ref":"ExZstdZig.GitInfo.html"},{"type":"function","doc":"Returns all git tags in the repository.","title":"ExZstdZig.GitInfo.all_tags/0","ref":"ExZstdZig.GitInfo.html#all_tags/0"},{"type":"function","doc":"Returns the current git branch name.","title":"ExZstdZig.GitInfo.branch_name/0","ref":"ExZstdZig.GitInfo.html#branch_name/0"},{"type":"function","doc":"Returns the current git commit hash.","title":"ExZstdZig.GitInfo.commit_hash/0","ref":"ExZstdZig.GitInfo.html#commit_hash/0"},{"type":"function","doc":"Returns the current git tag (if any) pointing to HEAD.","title":"ExZstdZig.GitInfo.current_tag/0","ref":"ExZstdZig.GitInfo.html#current_tag/0"},{"type":"function","doc":"Returns comprehensive git information.","title":"ExZstdZig.GitInfo.info/0","ref":"ExZstdZig.GitInfo.html#info/0"},{"type":"function","doc":"Returns the latest git tag in the repository.","title":"ExZstdZig.GitInfo.latest_tag/0","ref":"ExZstdZig.GitInfo.html#latest_tag/0"},{"type":"function","doc":"Returns the short git commit hash.","title":"ExZstdZig.GitInfo.short_commit_hash/0","ref":"ExZstdZig.GitInfo.html#short_commit_hash/0"},{"type":"function","doc":"Returns git status information.","title":"ExZstdZig.GitInfo.status/0","ref":"ExZstdZig.GitInfo.html#status/0"},{"type":"function","doc":"Returns a formatted version string with git information.","title":"ExZstdZig.GitInfo.version_string/0","ref":"ExZstdZig.GitInfo.html#version_string/0"},{"type":"extras","doc":"# ExZstdZig\n\nFast Zstandard (zstd) compression/decompression for Elixir, implemented with Zig NIFs via the wonderful Zigler library.\n\n![Zig support](https://img.shields.io/badge/Zig-0.15.1-color?logo=zig&color=%23f3ab20)\n![Static Badge](https://img.shields.io/badge/zigler-0.15.1-orange)\n![Static Badge](https://img.shields.io/badge/zstd_1.5.7-green)\n\nZstandard is a fast compression algorithm offering high compression ratios. This library provides complete bindings with support for one-shot operations, streaming, context reuse, and dictionary training.","title":"ExZstdZig","ref":"readme.html"},{"type":"extras","doc":"- **Fast** - Native implementation using Zig with minimal overhead\n- **Streaming** - Process large files without loading them into memory\n- **Context reuse** - Better performance when compressing multiple items\n- **Dictionary support** - Improved compression for similar small files\n- **Compression strategies** - Optimized presets for different data types\n- **Complete API** - From simple one-shot to advanced streaming operations","title":"Features - ExZstdZig","ref":"readme.html#features"},{"type":"extras","doc":"Add `ex_zstd_zig` to your list of dependencies in `mix.exs`:\n\n```elixir\ndef deps do\n  [\n    {:ex_zstd_zig, \"~> 0.1.0\"}\n  ]\nend\n```","title":"Installation - ExZstdZig","ref":"readme.html#installation"},{"type":"extras","doc":"The library requires `libzstd` to be installed on your system:\n\n**macOS:**\n\n```bash\nbrew install zstd\n```\n\n**Ubuntu/Debian:**\n\n```bash\nsudo apt-get install libzstd-dev\n```","title":"System Requirements - ExZstdZig","ref":"readme.html#system-requirements"},{"type":"extras","doc":"","title":"Quick Start - ExZstdZig","ref":"readme.html#quick-start"},{"type":"extras","doc":"```elixir\n# Compress data\ndata = \"Hello, World!\"\n{:ok, compressed} = ExZstdZig.compress(data, 3)\n\n# Decompress\n{:ok, decompressed} = ExZstdZig.decompress(compressed)\n```","title":"Simple Compression - ExZstdZig","ref":"readme.html#simple-compression"},{"type":"extras","doc":"```elixir\n# Compress a file\n:ok = ExZstdZig.compress_file(\"input.txt\", \"output.txt.zst\")\n\n# Decompress a file\n:ok = ExZstdZig.decompress_file(\"output.txt.zst\", \"restored.txt\")\n```","title":"File Compression with streams - ExZstdZig","ref":"readme.html#file-compression-with-streams"},{"type":"extras","doc":"```elixir\n# Create a context once\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 5, strategy: :text})\n\n# Compress multiple items efficiently\n{:ok, compressed1} = ExZstdZig.compress_with_ctx(cctx, data1)\n\n# Reset and reuse\n:ok = ExZstdZig.reset_compressor_session(cctx)\n{:ok, compressed2} = ExZstdZig.compress_with_ctx(cctx, data2)\n```","title":"Context Reuse (Better Performance) - ExZstdZig","ref":"readme.html#context-reuse-better-performance"},{"type":"extras","doc":"```elixir\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3, strategy: :balanced})\n\n# Compress in chunks\n{:ok, {chunk1, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk1, :flush)\n{:ok, {chunk2, _, _}} = ExZstdZig.compress_stream(cctx, data_chunk2, :flush)\n{:ok, {final, _, _}} = ExZstdZig.compress_stream(cctx, <<>>, :end_frame)\n\ncompressed = IO.iodata_to_binary([chunk1, chunk2, final])\n```","title":"Streaming Compression - ExZstdZig","ref":"readme.html#streaming-compression"},{"type":"extras","doc":"Train a dictionary for better compression of many small similar files:\n\n```elixir\n# Collect sample data\nsamples = [\n  ~s({\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\"}),\n  ~s({\"id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\"}),\n  # ... more samples\n]\n\n# Train dictionary\n{:ok, dictionary} = ExZstdZig.train_dictionary(samples, 1024)\n\n# Compress with dictionary\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3, strategy: :structured_data})\n{:ok, compressed} = ExZstdZig.compress_with_dict(cctx, new_data, dictionary)\n\n# Decompress with dictionary\n{:ok, dctx} = ExZstdZig.dctx_init(nil)\n{:ok, decompressed} = ExZstdZig.decompress_with_dict(dctx, compressed, dictionary)\n```","title":"Dictionary Training - ExZstdZig","ref":"readme.html#dictionary-training"},{"type":"extras","doc":"Choose the right strategy for your data type:\n\n- `:fast` - Fastest compression (level 1)\n- `:balanced` - Good balance (level 3, **default**)\n- `:maximum` - Maximum compression (level 22)\n- `:text` - Optimized for text/code (level 9)\n- `:structured_data` - Optimized for JSON/XML (level 9)\n- `:binary` - Optimized for binary data (level 6)\n\nExample:\n\n```elixir\n# For JSON data\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 9, strategy: :structured_data})\n\n# For text files\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 9, strategy: :text})\n```","title":"Compression Strategies - ExZstdZig","ref":"readme.html#compression-strategies"},{"type":"extras","doc":"1. **Reuse contexts** - Creating contexts has overhead. Reuse them for multiple operations\n2. **Choose appropriate level** - Level 3 is usually optimal. Higher levels give diminishing returns\n3. **Use dictionaries** - For compressing many small similar files (< 1KB each)\n4. **Stream large files** - Use `compress_file/3` or streaming API for files > 100MB\n5. **Pick the right strategy** - Match the strategy to your data type","title":"Performance Tips - ExZstdZig","ref":"readme.html#performance-tips"},{"type":"extras","doc":"","title":"HTTP Streaming - ExZstdZig","ref":"readme.html#http-streaming"},{"type":"extras","doc":"You **can** compress data on-the-fly during HTTP downloads because compression is fast enough:\n\n```elixir\n{:ok, cctx} = ExZstdZig.cctx_init(%{compression_level: 3, strategy: :structured_data})\ncompressed_pid = File.open!(\"output.zst\", [:write, :binary])\n\nReq.get!(\"https://example.com/large-file.json\",\n  into: fn\n    {:data, chunk}, {req, resp} ->\n      # Compress each chunk as it arrives\n      {:ok, {compressed, _, _}} = ExZstdZig.compress_stream(cctx, chunk, :flush)\n      :ok = IO.binwrite(compressed_pid, compressed)\n      {:cont, {req, resp}}\n  end\n)\n\nFile.close(compressed_pid)\n```","title":"Compression: On-the-fly - ExZstdZig","ref":"readme.html#compression-on-the-fly"},{"type":"extras","doc":"You **cannot** decompress on-the-fly in HTTP callbacks due to HTTP/2 back-pressure limitations. Use a 2-step process:\n\n```elixir\n# Step 1: Download compressed file (fast callback)\ncompressed_pid = File.open!(\"download.zst\", [:write, :binary])\n\nReq.get!(\"https://example.com/compressed-file.zst\",\n  into: fn\n    {:data, chunk}, {req, resp} ->\n      :ok = IO.binwrite(compressed_pid, chunk)\n      {:cont, {req, resp}}\n  end\n)\n\nFile.close(compressed_pid)\n\n# Step 2: Decompress using streaming decompression\n{:ok, dctx} = ExZstdZig.dctx_init(nil)\nExZstdZig.decompress_file(\"download.zst\", \"output.txt\", dctx: dctx)\n```\n\n**Why?** HTTP/2 (used by Finch/Req) has no back-pressure mechanism. Decompression + file I/O in callbacks is too slow, causing connection timeouts and data loss.","title":"Decompression: 2-Step Process ⚠️ - ExZstdZig","ref":"readme.html#decompression-2-step-process-️"},{"type":"extras","doc":"","title":"API Overview - ExZstdZig","ref":"readme.html#api-overview"},{"type":"extras","doc":"- `compress/2` - Compress data, returns `{:ok, compressed}`\n- `decompress/1` - Decompress data, returns `{:ok, decompressed}`\n- `simple_compress/2` - Direct compression (raises on error)\n- `simple_auto_decompress/1` - Direct decompression (raises on error)","title":"One-shot Functions - ExZstdZig","ref":"readme.html#one-shot-functions"},{"type":"extras","doc":"- `cctx_init/1` - Create compression context\n- `dctx_init/1` - Create decompression context\n- `reset_compressor_session/1` - Reset compression context for reuse\n- `reset_decompressor_session/1` - Reset decompression context for reuse","title":"Context Management - ExZstdZig","ref":"readme.html#context-management"},{"type":"extras","doc":"- `compress_with_ctx/2` - Compress using context\n- `decompress_with_ctx/2` - Decompress using context","title":"Context-based Operations - ExZstdZig","ref":"readme.html#context-based-operations"},{"type":"extras","doc":"- `compress_stream/3` - Compress data in chunks\n- `decompress_stream/2` - Decompress data in chunks\n- `recommended_c_in_size/0` - Get recommended input buffer size for compression\n- `recommended_d_in_size/0` - Get recommended input buffer size for decompression","title":"Streaming - ExZstdZig","ref":"readme.html#streaming"},{"type":"extras","doc":"- `compress_file/3` - Compress file (streaming, low memory)\n- `decompress_file/3` - Decompress file (streaming, low memory)","title":"File Operations - ExZstdZig","ref":"readme.html#file-operations"},{"type":"extras","doc":"- `train_dictionary/2` - Train dictionary from samples\n- `load_compression_dictionary/2` - Load dictionary into compression context\n- `load_decompression_dictionary/2` - Load dictionary into decompression context\n- `compress_with_dict/3` - One-shot compression with dictionary\n- `decompress_with_dict/3` - One-shot decompression with dictionary","title":"Dictionary Support - ExZstdZig","ref":"readme.html#dictionary-support"},{"type":"extras","doc":"- `getDecompressedSize/1` - Get decompressed size from compressed data\n- `version/0` - Get zstd library version","title":"Utilities - ExZstdZig","ref":"readme.html#utilities"},{"type":"extras","doc":"Full documentation is available at [HexDocs](https://hexdocs.pm/ex_zstd_zig) (once published).\n\nTo generate documentation locally:\n\n```bash\nmix docs\n```\n\nThen open `doc/index.html` in your browser.","title":"Documentation - ExZstdZig","ref":"readme.html#documentation"},{"type":"extras","doc":"MIT License - see [LICENSE](LICENSE) for details.","title":"License - ExZstdZig","ref":"readme.html#license"},{"type":"extras","doc":"- Built with [Zigler](https://github.com/E-xyza/zigler)\n- Uses [Zstandard](https://facebook.github.io/zstd/) compression library","title":"Credits - ExZstdZig","ref":"readme.html#credits"}],"proglang":"elixir","content_type":"text/markdown","producer":{"name":"ex_doc","version":"0.38.4"}}